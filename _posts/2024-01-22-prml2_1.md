---
title: PRML [2.1] 이산 확률 변수
date: 2024-01-22
categories: ["2024", "PRML"]
tags: ["Bernoulli distribution", "sufficient statistic", "Binary distribution", "conjugate", "Beta distribution"]
use_math: true
---


### 베르누이 분포

동전 던지기 같은 이진 확률 변수 $x \in \{0, 1\}$을 생각해보자. $x = 1$이 앞면, $x = 0$이 뒷면인데, 두 확률이 동일하지 않다고 하자. 

$x = 1$일 확률을 매개변수 $\mu$ 를 통해 다음과 같이 표현할 수 있다.

$$
p(x = 1|\mu)=\mu \tag{2.1}
$$

- $0 \leq \mu \leq 1$
- 동전이 뒷면일 때의 확률은 $p(x = 0\|\mu)=1-\mu$

따라서, $x$에 대한 확률 분포는 다음과 같이 나타낼 수 있다.

$$
Bern(x|\mu)=\mu ^x (1-\mu)^{1-x} \tag{2.2}
$$

이것을 **베르누이 분포 (Bernoulli Distribution)**라고 한다.

베르누이 분포의 평균과 분산은 다음과 같다.

$$
E[x]=\mu \tag{2.3}
$$

$$
var[x]=\mu (1-\mu) \tag{2.4}
$$

관측 데이터 집합 $D=\{x_1, ..., x_N\}$이 주어졌을 때, $\mu$에 대해서 이 관측 값을 얻을 확률(가능도 함수)을 다음과 같이 나타낼 수 있다.

$$
p(D|\mu)=\prod_{n=1}^{N}p(x_n|\mu)=\prod_{n=1}^{N}\mu^{x_n}(1-\mu)^{1-x_n} \qquad{(2.5)}
$$

이 가능도 함수를 최대화하는 $\mu$를 찾아서 $\mu$ 값을 추정할 수 있다. 베르누이 분포의 로그 가능도 함수는 아래와 같다.

$$
\ln p(D|\mu)=\sum_{n=1}^{N}\ln p(x_n|\mu)=\sum_{n=1}^{N}\left\{x_n\ln\mu+(1-x_n)\ln(1-\mu)\right\} \qquad{(2.6)}
$$

이 로그 가능도 함수에는 관측된 데이터의 개수 N과 관측된 데이터의 값 $x_n$에 영향을 받는다. 식 2.6을 재구성하면 다음과 같다.

$$
\ln p(D∣μ)=(∑_{n=1}^N x_n)\ln μ+(N−∑_{n=1}^N x_n)\ln (1−μ)
$$

로그 가능도 함수는 오직 $\sum_n x_n$을 통해서만 N 개의 관측값 $x_n$과 연관된다. 베르누이 분포에서 각 시행의 결과가 1 또는 0이기 때문에, 로그 가능도는 동전이 앞면인 획수의 총합에만 의존한다는 것이다.  이 합을 충분 통계량으로 본다.

- **충분 통계량(sufficient statistic)** : 데이터 집합의 주요 정보를 요약하는 통계량. 원래 데이터 집합을 사용하는 것과 동일한 추정을 할 수 있게 도와준다.

어쨌든, 이 가능도 함수를 $\mu$에 대해 미분하면 $\mu$ 값을 추정할 수 있다.

$$
\begin{align}
\mu_{ML}&=\dfrac{1}{N}\sum_{n=1}^{N}x_n \qquad{(2.7)} \notag \\&=\dfrac{m}{N} \qquad{(2.8)} \notag
\end{align}
$$

식 2.7을 표본 평균으로 본다. 데이터에서 $x = 1$인 관찰값의 개수를 $m$이라고 하면 2.8로도 표현 가능하다.

식 2.8을 보면 결국은 { 앞면 / 전체 } 이다.

이렇게 예측을 할 때 문제점이 있다. 세 번 던져서 모두 앞면이 나오면 $\mu_{ML}=1$이 되고, 앞으로 받을 모든 데이터가 1이라고 예측한다. 사전 분포를 바탕으로 오버피팅을 해결할 수 있다. → see you later

---

### 이항 분포

동전을 $N$번 던져서 앞면이 $m$번 나오는, 가능한 모든 경우의 수는 다음과 같은 이항 분포로 나타낼 수 있다. 

$$
Bin(m|N, \mu)=\dbinom{N}{m}\mu^m(1-\mu)^{N-m} \qquad{(2.9)}
$$

<img width="525" alt="binary distribution" src="https://github.com/ajinjink/ajinjink/assets/105297115/ae8be87e-49d2-44be-b846-ab92a969cc5b" style="zoom:50%;">

위 그림은 $N = 10$, $\mu = 0.25$ 일 때 $m$에 대해서 나타낸 이항 분포의 히스토그램이다. 

동전을 10번 던지고, 앞면이 나올 확률이 0.25일 때, 앞면이 나온 개수의 분포라고 생각할 수 있겠다. $10 \times 0.25 = 2.5$ 이고, 실제로 분포에서 2와 3이 값이 가장 큰 걸 알 수 있다.

이항 분포의 평균과 분산은 다음과 같다.

$$
E[m]\equiv\sum_{m=0}^{N}m \cdot Bin(m|N, \mu)=N\mu \qquad{(2.11)}
$$

$$
var[m]\equiv\sum_{m=0}^{N}(m-E[m])^2Bin(m|N,\mu)=N\mu(1-\mu) \qquad{(2.12)}
$$

---

### 베르누이 분포 vs 이항분포

- 베르누이 분포는 단일 시행에서 두 가지 결과만을 갖는 상황에서 사용되며, 보통 1 또는 0으로 표현된다.
- 베르누이 분포의 확률 질량 함수 $Bern(x\|\mu)=\mu ^x (1-\mu)^{1-x}$
- 이항 분포는 독립적인 베르누이 시행을 n번 반복했을 때의 특정 결과값이 나타나는 횟수에 대한 분포이다.
- 이상 분포의 확률 질량 함수 $Bin(m\|N, \mu)=\dbinom{N}{m}\mu^m(1-\mu)^{N-m}$

---

## 2.1.1 베타 분포

MLE를 사용했을 때, 베르누이 분포에서 오버피팅이 일어나는 것을 확인했었다. (3번 던져서 앞면만 3번 나오면 앞면만 나올 거라고 예측하기)

이를 베이지안적으로 접근하려면 매개변수 $\mu$에 대한 사전 분포 $p(\mu)$를 도입해야 한다.

가능도 함수가 $\mu^x (1-\mu)^{1-x}$의 형태를 갖고 있다. 사전 분포의 형태를 $\mu^n (1-\mu)^m$  형태로 잡으면, 사후 분포는 { 사전 확률 $\times$ 가능도 함수 } 에 비례하므로, 사전 분포와 함수 형태가 같아질 것이다. 이런 속성을 **켤레성 (conjugacy)**라고 한다.

따라서, 사전 분포로 베타 분포(Beta distribution)를 사용한다.

$$
Beta(\mu|a, b) = \frac{\Gamma(a+b)}{\Gamma(a)\;\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1} \qquad{(2.13)}
$$

- $\frac{\Gamma(a+b)}{\Gamma(a)\;\Gamma(b)}$ : 정규화 상수
- $\Gamma(x)=\int_0^\infty u^{x-1}e^{-u}du$

cf) 켤레성

- 사전 분포와 사후 분포가 같은 분포 family에 속함.
- 사전 분포가 베타분포이면, 사후 분포도 베타 분포의 형태로 나타남.
- 따라서, 베이지안 분석 계산을 간단히 만듦.

$$
\int_{0}^{1}Beta(\mu|a,b)d\mu=1 \qquad{(2.14)}
$$

베타 분포는 정규화되어 있기 때문에 합이 1이고, 베타 분포의 평균과 분산은 다음과 같이 나타난다. 

$$
E[\mu] = \dfrac{a}{a+b} \qquad{(2.15)}
$$

$$
var[\mu] = \dfrac{ab}{(a+b)^2(a+b+1)} \qquad{(2.16)}
$$

사전 분포로 베타 분포 $Beta(\mu\|a, b)$를 사용할 때, $a$, $b$는 이 분포의 매개벼수로 사용이 된다. 사전 지식, 믿음을 나타내고 베타 분포의 형태를 결정하는 초매개변수(hyperparameter)로 작용한다.

<img width="704" alt="Beta distribution" src="https://github.com/ajinjink/ajinjink/assets/105297115/4d07eb6c-8608-4d60-87ca-1a5c85fc9bdc">

위 그래프는 $a$, $b$ 값에 따른 베타 분포이다.

---

사후 분포의 형태는 다음과 같다.

$$
p(\mu|m, l, a, b) \propto \mu^{m+a-1}(1-\mu)^{l+b-1} \qquad{(2.17)}
$$

- $m$ : 앞면 개수
- $l$ : 뒷면 개수
- 사후 분포의 kernel(정규화 되지 않은 형태)이다.
- $\mu^{a-1}(1-\mu)^{b-1}$ 과 비교하면 가능도 함수에 대하여 사전 분포가 켤레적인 성질을 가지고 있다는 것을 확인할 수 있다.

새로운 베타 분포의 정규화 계수는 다음과 같이 적용해서 적을 수 있다.

$$
p(\mu|m, l, a, b) = \dfrac{\Gamma(m+a+l+b)}{\Gamma(m+a)\Gamma(l+b)}\mu^{m+a-1}(1-\mu)^{l+b-1} \qquad{(2.18)}
$$

- 사전 분포 :  $\dfrac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \mu^{a-1} (1-\mu)^{b-1}$

사전 분포에 비교해서 사후분포에서 $a$와 $b$가 각각 $m$, $l$만큼 증가한 것을 확인할 수 있다. 여기서 사전 분포의 hyperparameter $a$, $b$를 각각 $x = 1$, $x = 0$인 경우에 대한 **유효 관찰수 (effective number of observations)**라고 한다. 데이터를 받아서 계속 사후 분포를 업데이트 할 때, 사후 분포는 $x = 1$과 $x = 0$에 해당하는 관측값들의 전체 숫자가 새로운 $a$와 $b$ 값으로 주어지는 베타 분포에 해당한다.

- $a, b$ : 사전 분포의 매개변수
- $m, l$ : 새로운 과측 데이터
- 새로운 관측값이 주어질 때, 사후 분포의 업뎃은 사전분포의 $a$와 $b$에 $m$과 $l$을 더해서 이루어짐 → 사전 지식이 새로운 데이터에 의해 수정됨
    
    <img width="763" alt="sequential Bayesian" src="https://github.com/ajinjink/ajinjink/assets/105297115/74fb77af-8960-4895-8345-c7c6efc6f435">
    

---

### 순차적 방법론 (sequential approach)

베이지안 관점을 통해 이렇게 하나씩 업데이트 하는 순차적인 접근이 가능해진다. 관측값을 한 번에 하나(또는 조금)만 사용하고, 다음 관측값을 사용하기 전에 버린다. 전체 데이터 집합이 메모리에 로드되거나 저장될 필요가 없어 실시간 학습을 할 때에 사용하기 좋다. 최대 가능도 방법론도 순차적 방법론 하에서 사용 가능하다.

다음 시도의 결괏값을 잘 예측하는 것이 목표라면, 관측 데이터 집합 *D*가 주어진 상황에서 $x$의 예측 분포를 계산해야 한다. 식 2.19는 *D*가 주어졌을 때, 다음 시도에서 $x = 1$이 될 확률이다.

$$
p(x=1|D)=\int_0^1 p(x=1|\mu)p(\mu|D)d\mu = \int_0^1 \mu p(\mu|D) d\mu = E[\mu|D] \qquad{(2.19)}
$$

- $p(x=1\|\mu)$ : $\mu$ 주어졌을 때, $x = 1$일 확률
- $p(\mu\|D)$ : *D* 주어졌을 때, $\mu$의 사후 분포
- $\int_0^1 p(x=1\|\mu)p(\mu\|D)d\mu$ : 가능한 모든 $\mu$에 대한 평균 ($x = 1$일 전체 확률)
- $\int_0^1 \mu p(\mu\|D) d\mu$ : $\mu$ 의 기댓값 ($\because$ 애초에 이진 확률 변수에서 $\mu$ 자체가 $x = 1$일 확률.)

주어진 데이터에 대한 평균값을 구하는 것이므로, $E[\mu] = \dfrac{a}{a+b}$ 에 따라 다음과 같이 나타낼 수 있다.

$$
p(x=1|D) = \dfrac{m+a}{m+a+l+b} \qquad{(2.20)}
$$

여기서 데이터 크기가 매우 커져서 $m, l → \infty$ 가 된다면, $p(x=1\|D)$ 의 값은 $\mu_{ML}=\dfrac{m}{N}$ 와 같아진다.

베타 분포 설명할 때, $a, b$에 따라 변화하는 사후분포를 보면, 관측값의 수가 늘어날 수록 사후 분포가 더 평균에 몰리는 것을 확인할 수 있다. (더 날카롭고 뾰족해진다) 데이터를 더 많이 관찰할 수록 사후 분포의 불확실성의 정도가 감소한다는 것을 이해해보자.

관측된 데이터 집합 *D*에 대해서 매개변수 $\theta$를 추정하는 베이지안 추론 문제를 살펴보자. 이 문제를 결합 분포 $p(\theta,D)$로 표현 가능하다. 매개변수 $\theta$에 대한 기댓값은 다음과 같다.

$$
E_{\theta}[\theta] = E_D[E_{\theta}[{\pmb \theta}|D]] \qquad{(2.21)}
$$

- $E_{\theta}[\theta]$ : $\theta$의 전체 기댓값
- $E_D[E_{\theta}[{\pmb \theta}\|D]]$ : (*D*에 대한 $\theta$의 조건부 기댓값)의 기댓값
- 결국, 기댓값의 기댓값 = 기댓값 이라는 것을 알 수 있다.

$$
E_[{\pmb \theta}] \equiv \int p({\pmb \theta}){\pmb \theta} d{\pmb \theta} \qquad{(2.22)}
$$

- $p({\pmb \theta})$ : 사전분포(가중치)
- $\theta$의 모든 가능한 값에 대해 $\theta$를 가중치로 하는 평균을 취하여 계산

$$
E_D[E_{\theta}[{\pmb \theta}|D]] \equiv \int\left\{\int{\pmb \theta} p({\pmb \theta}|D)d{\pmb \theta}\right\}p(D)dD \qquad{(2.23)}
$$

- $\int{\pmb \theta} p({\pmb \theta}\|D)d{\pmb \theta}$ : *D* 주어졌을 때 $\theta$의 조건부 기댓값
- 결국, $E_D[E_{\theta}[{\pmb \theta}\|D]]$ = 모든 가능한 *D*에 대한 조건부 기댓값의 기댓값

따라서, { 데이터가 생성된 원 분포에 대해 평균을 낸 $\theta$의 사후 평균값 (식 2.23) }은 { $\theta$의 사전 평균 (식 2.22) }과 같다.

이와 같이 분산도 다음과 같이 나타난다.

$$
var_{\theta}[{\pmb \theta}] = E_D[var_{\theta}[{\pmb \theta}|D]] + var_D[E_{\theta}[{\pmb \theta}|D]] \qquad{(2.24)}
$$

- $var_{\theta}[{\pmb \theta}]$ : $\theta$의 사전 분산
- $E_D[var_{\theta}[{\pmb \theta}\|D]]$ : { $\theta$의 사후 분산 }의 평균 ≤ $var_{\theta}[{\pmb \theta}]$
- $var_D[E_{\theta}[{\pmb \theta}\|D]]$  : { $\theta$의 사후 평균 }의 분산 ≥ 0

우변에서 두 번째 항이 양의 값을 가지므로, 첫 번째 항이 좌변의 값보다 작다는 것을 알 수 있다. 즉, 평균적으로 $\theta$의 사후 분산은 사전 분산보다 작다는 것이다.