---
title: PRML [1.4] 차원의 저주
date: 2024-01-11
categories: ["2024", "PRML"]
tags: ["Gaussian distribution"]
use_math: true
---


데이터가 이진이나 단변량으로 들어오는 경우가 거의 없다. 아래 그림과 같이 하나의 데이터 포인트가 여러 요소를 가질 수 있고, 이를 구별해 내야 한다.

아래 그림에서 x 표가 어느 집단에 속하는지 판별을 하고 싶다. 가장 쉬운 방법은 입력 공간을 여러 칸으로 나누어서, 각 칸에서 다수를 차지하는 클래스를 해당 칸에 할당하는 것이다. 그러면 x는 빨간 칸에 속하기 되기 때문에, 빨간 데이터 클래스로 판별을 할 수 있다.

<img width="1018" alt="스크린샷 2024-01-12 오전 1 28 38" src="https://github.com/ajinjink/ajinjink/assets/105297115/78223085-732c-4251-ac69-6e6a07f20238" style="zoom:50%;" >

참 단순하고 좋은데, 이제 데이터가 다차원으로 올라가면 이렇게 칸을 나누는 게 쉽지 않다는 것이다. 데이터가 {키, 몸무게, 운동능력}과 같이 들어오면 3차원에서 입력 공간을 나누어야 한다. 3차원이 아니라 $D$ 차원이 되면, 셀 숫자가 기하급수적으로 증가하는데, 어떻게 나눌 건데…

<img alt="스크린샷 2024-01-12 오전 1 30 44" src="https://github.com/ajinjink/ajinjink/assets/105297115/2981bf98-53f4-4f3f-ad53-f01927da2b1a" style="zoom: 33%;" >

$D$개의 입력 변수에 대해서 판별 함수는 다음과 같다.

$$ y({\bf x}, {\bf w})=w_0+\sum_{i=1}^{D}{w_i}{x_i} + \sum_{i=1}^{D}\sum_{j=1}^{D}{w_{ij}}{x_i}{x_j}+\sum_{i=1}^{D}\sum_{j=1}^{D}\sum_{k=1}^{D}{w_{ijk}}{x_i}{x_j}{x_k} \qquad{(식\ 1.74)} $$

앞에서 본 $M$차 다항식을 사용하면, 차수는 $D^M$에 비례하여 증가한다.

------

고차원 공간에서의 가우시안 분포를 살펴보기 전에 예시를 하나만 살펴보자.

$D$ 차원의, 반지름 $r = 1$ 인 구가 있다고 하자. $r = 1$ 인 구와 $r = 1 - \epsilon$ 인 구의 비율 차이를 계산해보자.

$D$ 차원에서 반지름이 $r$인 구의 부피는 $r^D$ 에 비례하여 증가하므로, 부피식은 다음과 같이 표현할 수 있다.

$$ V_D (r)=K_D r^D \tag{식 1.75} $$

두 구의 부피 비율을 계산해보면 다음과 같다.

$$ {V_D(1)-V_D(1-\epsilon)\over V_D(1)}=1 - (1-\epsilon)^D \tag{식 1.76} $$

식의 우변을 보면 알 수 있듯이, $D$가 증가할 수록 $(1-\epsilon)^D$ 값이 감소하여, 비율 차이가 감소한다. 즉, 차원이 높아지면 반지름이 $r=1-\epsilon$ 인 구가 점점 $r=1$ 인 구의 표면에 접근하여, 두 구가 매우 가까워진다는 것이다.

<img alt="스크린샷 2024-01-12 오전 1 31 48" src="https://github.com/ajinjink/ajinjink/assets/105297115/9cad8467-d24b-4695-8120-8531f0089826" style="zoom: 33%;" >

------

고차원 공간에서의 가우시안 분포로 돌아오자.

데카르트 좌표에서 극좌표로 변환한 뒤에 방향성 변수들을 적분시켜 없애면 원점에서부터의 반지름 $r$상에 $\delta r$의 두께에 해당하는 확률 질량을 나타내게 된다.

- 수학적으로 이해는 제대로 못 했지만, 화학에서의 오비탈과 비슷하다고 이해했다.

<img width="454" alt="스크린샷 2024-01-12 오전 1 32 37" src="https://github.com/ajinjink/ajinjink/assets/105297115/85eaea7d-4644-40d6-87c2-328681977874" style="zoom:50%;" >

이 분포를 보면, 큰 $D$ 값에 대하여, 가우시안 확률 질량이 얇은 겉껍질에 집중되는 것을 확인할 수 있다. 이는 고차원에서 데이터 포인트가 중심보다는 가장자리에 몰리는 경향을 나타낸다.

**차원의 저주(Curse of Dimensionality)**는 고차원 공간에서 데이터 분석과 처리를 어렵게 만드는 다양한 문제들을 일컫는 말인데, 지금 이 현상도 차원의 저주와 관련이 있다. 고차원 공간에서 거리 기반의 알고리즘들이 예상과 다르게 작동할 수 있음을 의미하는 것이다.

그러면 고차원에서는 판별이 불가능한가? 그건 아니다.

- 실제로 고차원 데이터에서 유의미한 차원의 수는 제한적이다
- 실제 데이터는 (최소한 국소적으로라도) smoothness를 띄기 때문에, 입력값에서 조금의 변화가 일어나도 차원이 다 뒤집어지는 게 아니라 표적값도 조금 변화한다.
  - 지역 보간법 같은 방법을 통해 타깃 변수가 예측 가능하다.

예시)

컨베이어 벨트 위에 있는 물체들의 이미지를 캡처하여, 물체의 모양을 판단하고 싶다고 하자. 각 이미지는 고차원 공간에서의 포인트이고, 픽셀 수에 의해 공간의 차원이 결정된다.

각 물체는 이미지 내에서 다른 위치에 나타날 것이므로 3 단계의 자유도를 가진다 (위치, 방향, 크기). 따라서, 이 고차원의 데이터는 3차원 매니폴드(manifold) 위에 존재하며, 위치, 모양, 픽셀 형태로 구성된 복잡한 관계로 인해 매니폴드는 비선형성을 띈다.

물체의 방향만 알고 싶으면 3차원 매니폴드에서 변수 하나만 고려하면 된다 (중요한 자유도가 한 개).